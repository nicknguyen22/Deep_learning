---
title: "Modelling with Support Vector Machine (SVM) Algorithms via the Caret Pipeline"
author: "Hieu Nguyen"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

This is an R-Markdown Notebook create a sequence or pipeline of data transformations and machine learning operations using the caret package. The pipeline will develop a model to classify Breast-Cancer cases using Support Vector Machine Algorithms.


By creating a Caret pipeline, you can streamline and automate these steps, making it easier to experiment with different algorithms and configurations while ensuring consistent preprocessing and evaluation procedures. This facilitates efficient and reproducible machine learning workflows in R.


## Environment

First we shall load the necessary packages
```{r include=FALSE}
library(summarytools)
library(caret)
library(recipes)
library(embed)
library(themis)
library(kernlab)
library(ggplot2)
library(ggalluvial)
set.seed(7903)
```

## Data
We shall now load the data and summarise it
```{r}
data <- read.csv(file = "breast-cancer.csv", stringsAsFactors = TRUE)
str(data)
```

## Test/train
We need to separate test from train as early as possible
```{r}
index <- caret::createDataPartition(y = data$diagnosis, p = 0.7, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
```

## Preprocessing
The recipe will be as follows:

 * diagnosis is the target
 * id is the identifier
 * up-sample the minority class
 * normalise the numeric predictors 
 * experiment with dimensional reduction to 5 components
  
```{r}
recipe5 <- recipe(diagnosis ~., data = train) %>% 
  update_role(id, new_role = "id") %>% 
  step_bsmote(diagnosis) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_umap(all_numeric_predictors(), outcome = "diagnosis", num_comp = 5)
```  

## Modeling (SVM)

This preprocessing can be used with an SVMRadial method
```{r}
trainCont <- trainControl(method = "cv", number = 10, summaryFunction = twoClassSummary, classProbs = TRUE)
model_svmRad5 <- recipe5 %>% 
  train(data = train, method = "svmRadial", trControl = trainCont, metric = "ROC")
model_svmRad5
```

## Assessment
What does this mean for unseen data?
```{r}
results <- predict(model_svmRad5, newdata = test)
actual <- test$diagnosis
caret::confusionMatrix(results, actual)
```

## Repeat for 10 components

Let's try this for `num_comp = 10`
```{r}
recipe10 <- recipe(diagnosis ~., data = train) %>% 
  update_role(id, new_role = "id") %>% 
  step_bsmote(diagnosis) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_umap(all_numeric_predictors(), outcome = "diagnosis", num_comp = 10)
model_svmRad10 <- recipe10 %>% 
  train(data = train, method = "svmRadial", trControl = trainCont, metric = "ROC")
results <- predict(model_svmRad10, newdata = test)
actual <- test$diagnosis
caret::confusionMatrix(results, actual)
```  

```{r}
model_svmRad10
```


## Repeat for 15 components

Let's try this for `num_comp = 15`

```{r}
recipe15 <- recipe(diagnosis ~., data = train) %>% 
  update_role(id, new_role = "id") %>% 
  step_bsmote(diagnosis) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_umap(all_numeric_predictors(), outcome = "diagnosis", num_comp = 15)
model_svmRad15 <- recipe15 %>% 
  train(data = train, method = "svmRadial", trControl = trainCont, metric = "ROC")
results <- predict(model_svmRad15, newdata = test)
actual <- test$diagnosis
caret::confusionMatrix(results, actual)
```  

## Conclusion

Using 10 UMAP components seems optimal but the difference is minor. The expected accuracy is 97.7% based upon the test data. 

```{r}
model_svmRad10
```



The "test" confusion matrix can be visualised using an alluvial plot.

```{r}
results <- predict(model_svmRad15, newdata = test)
actual <- test$diagnosis
cm <- caret::confusionMatrix(results, actual)
cm
```



```{r}
data <- as.data.frame(cm$table)
data$missclassified <- data$Prediction != data$Reference
ggplot(data = data, mapping = aes(y = Freq, axis1 = Prediction, axis2 = Reference, label = after_stat(stratum))) +
  ggalluvial::geom_alluvium(aes(fill = missclassified, colour = missclassified), show.legend = TRUE) +
  ggalluvial::geom_stratum(width = 0.2) +
  geom_text(stat = "stratum", reverse = TRUE) +
  scale_x_discrete(limits = c("Prediction", "Actual"), expand = c(0.0, 0.0)) +
  ggtitle("Classification of Breast-cancer diagnoses") +
  scale_fill_manual(values = c("green","red")) +
  theme_bw()
```
